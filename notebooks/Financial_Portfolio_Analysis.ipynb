{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Portfolio Analysis\n",
    "## Top 5 Tech Stocks: AAPL, MSFT, GOOGL, NVDA, TSLA\n",
    "\n",
    "Analysis Period: 2023-01-01 to 2025-11-22"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Objectives\n",
    "\n",
    "This analysis aims to:\n",
    "1. **Fetch and analyze historical stock data** for major tech companies\n",
    "2. **Calculate risk metrics** including returns, volatility, and Sharpe ratios\n",
    "3. **Analyze correlations** between stocks to understand portfolio diversification\n",
    "4. **Compare portfolio strategies** (Equal-weight vs. Inverse-volatility weighted)\n",
    "5. **Generate comprehensive visualizations** and reports for investment insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yfinance as yf\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 6)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Fetching\n",
    "\n",
    "We'll fetch historical stock data for 5 major tech companies using the yfinance library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "tickers = ['AAPL', 'MSFT', 'GOOGL', 'NVDA', 'TSLA']\n",
    "start_date = '2023-01-01'\n",
    "end_date = '2025-11-22'\n",
    "\n",
    "print(f\"Fetching data for: {', '.join(tickers)}\")\n",
    "print(f\"Period: {start_date} to {end_date}\\n\")\n",
    "\n",
    "# Download data\n",
    "stock_data = yf.download(tickers, start=start_date, end=end_date, group_by='column')\n",
    "\n",
    "print(f\"\\nData shape: {stock_data.shape}\")\n",
    "print(f\"Number of trading days: {len(stock_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"First 5 rows of Close prices:\")\n",
    "stock_data['Close'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = stock_data.isnull().sum()\n",
    "print(\"Missing values per column:\")\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values!\")\n",
    "\n",
    "# Basic statistics\n",
    "print(\"\\nBasic Statistics for Close Prices:\")\n",
    "stock_data['Close'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Returns Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract close prices and calculate daily returns\n",
    "close_prices = stock_data['Close']\n",
    "daily_returns = close_prices.pct_change().dropna()\n",
    "\n",
    "print(\"Daily Returns - First 10 rows:\")\n",
    "print(daily_returns.head(10))\n",
    "\n",
    "print(\"\\nDaily Returns Summary Statistics:\")\n",
    "daily_returns.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cumulative returns\n",
    "cumulative_returns = (1 + daily_returns).cumprod() - 1\n",
    "\n",
    "# Plot cumulative returns\n",
    "plt.figure(figsize=(14, 6))\n",
    "for col in cumulative_returns.columns:\n",
    "    plt.plot(cumulative_returns.index, cumulative_returns[col] * 100, label=col, linewidth=2)\n",
    "\n",
    "plt.title('Cumulative Returns Over Time', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Return (%)', fontsize=12)\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFinal Cumulative Returns:\")\n",
    "print(cumulative_returns.iloc[-1] * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Risk Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annualized metrics\n",
    "def calculate_metrics(returns):\n",
    "    total_return = (1 + returns).prod() - 1\n",
    "    num_days = len(returns)\n",
    "    annualized_return = (1 + total_return) ** (252 / num_days) - 1\n",
    "    annualized_volatility = returns.std() * np.sqrt(252)\n",
    "    sharpe_ratio = (annualized_return - 0.02) / annualized_volatility\n",
    "    return annualized_return, annualized_volatility, sharpe_ratio\n",
    "\n",
    "# Calculate for each stock\n",
    "metrics_data = []\n",
    "for ticker in daily_returns.columns:\n",
    "    ann_ret, ann_vol, sharpe = calculate_metrics(daily_returns[ticker])\n",
    "    metrics_data.append({\n",
    "        'Ticker': ticker,\n",
    "        'Annualized Return': f\"{ann_ret:.2%}\",\n",
    "        'Annualized Volatility': f\"{ann_vol:.2%}\",\n",
    "        'Sharpe Ratio': f\"{sharpe:.3f}\"\n",
    "    })\n",
    "\n",
    "metrics_df = pd.DataFrame(metrics_data)\n",
    "print(\"Risk Metrics by Stock:\")\n",
    "print(metrics_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation matrix\n",
    "correlation_matrix = daily_returns.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8}, fmt='.3f')\n",
    "plt.title('Correlation Matrix Between Stocks', fontsize=16, fontweight='bold', pad=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation Matrix:\")\n",
    "print(correlation_matrix.round(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Portfolio Construction\n",
    "\n",
    "We'll compare two portfolio strategies:\n",
    "1. **Equal-Weight Portfolio**: 20% allocation to each stock\n",
    "2. **Inverse-Volatility Portfolio**: Weight inversely proportional to volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equal-weight portfolio\n",
    "equal_weights = {ticker: 0.20 for ticker in daily_returns.columns}\n",
    "eq_portfolio_returns = (daily_returns * 0.20).sum(axis=1)\n",
    "\n",
    "# Inverse-volatility portfolio\n",
    "stock_volatilities = daily_returns.std()\n",
    "inverse_vols = 1 / stock_volatilities\n",
    "inv_vol_weights = (inverse_vols / inverse_vols.sum()).to_dict()\n",
    "iv_portfolio_returns = (daily_returns * (inverse_vols / inverse_vols.sum())).sum(axis=1)\n",
    "\n",
    "# Display weights\n",
    "weights_df = pd.DataFrame({\n",
    "    'Ticker': list(equal_weights.keys()),\n",
    "    'Equal Weight': [f\"{v:.2%}\" for v in equal_weights.values()],\n",
    "    'Inverse-Vol Weight': [f\"{inv_vol_weights[k]:.2%}\" for k in equal_weights.keys()]\n",
    "})\n",
    "\n",
    "print(\"Portfolio Weights Comparison:\")\n",
    "print(weights_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate portfolio metrics\n",
    "def portfolio_metrics(returns, name):\n",
    "    ann_ret, ann_vol, sharpe = calculate_metrics(returns)\n",
    "    cumulative = (1 + returns).cumprod()\n",
    "    running_max = cumulative.expanding().max()\n",
    "    drawdown = (cumulative - running_max) / running_max\n",
    "    max_dd = drawdown.min()\n",
    "    \n",
    "    return {\n",
    "        'Portfolio': name,\n",
    "        'Annualized Return': f\"{ann_ret:.2%}\",\n",
    "        'Annualized Volatility': f\"{ann_vol:.2%}\",\n",
    "        'Sharpe Ratio': f\"{sharpe:.3f}\",\n",
    "        'Max Drawdown': f\"{max_dd:.2%}\"\n",
    "    }\n",
    "\n",
    "portfolio_comparison = pd.DataFrame([\n",
    "    portfolio_metrics(eq_portfolio_returns, 'Equal Weight'),\n",
    "    portfolio_metrics(iv_portfolio_returns, 'Inverse Volatility')\n",
    "])\n",
    "\n",
    "print(\"Portfolio Performance Comparison:\")\n",
    "print(portfolio_comparison.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot portfolio comparison\n",
    "eq_cumulative = (1 + eq_portfolio_returns).cumprod() - 1\n",
    "iv_cumulative = (1 + iv_portfolio_returns).cumprod() - 1\n",
    "\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.plot(eq_cumulative.index, eq_cumulative * 100, label='Equal Weight', linewidth=2.5)\n",
    "plt.plot(iv_cumulative.index, iv_cumulative * 100, label='Inverse Volatility', linewidth=2.5)\n",
    "plt.title('Portfolio Strategies Comparison', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Date', fontsize=12)\n",
    "plt.ylabel('Cumulative Return (%)', fontsize=12)\n",
    "plt.legend(loc='best', fontsize=12)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Risk vs Return Scatter Plot\n",
    "fig, ax = plt.subplots(figsize=(12, 8))\n",
    "\n",
    "ann_returns = []\n",
    "ann_vols = []\n",
    "sharpe_ratios = []\n",
    "\n",
    "for ticker in daily_returns.columns:\n",
    "    ann_ret, ann_vol, sharpe = calculate_metrics(daily_returns[ticker])\n",
    "    ann_returns.append(ann_ret * 100)\n",
    "    ann_vols.append(ann_vol * 100)\n",
    "    sharpe_ratios.append(sharpe)\n",
    "\n",
    "scatter = ax.scatter(ann_vols, ann_returns, c=sharpe_ratios, cmap='viridis',\n",
    "                     s=500, alpha=0.7, edgecolors='black', linewidth=2)\n",
    "\n",
    "for i, ticker in enumerate(daily_returns.columns):\n",
    "    ax.text(ann_vols[i], ann_returns[i], ticker, fontsize=12, fontweight='bold',\n",
    "            ha='center', va='center')\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Sharpe Ratio', fontsize=12)\n",
    "\n",
    "ax.set_xlabel('Annualized Volatility (Risk) %', fontsize=12)\n",
    "ax.set_ylabel('Annualized Return %', fontsize=12)\n",
    "ax.set_title('Risk vs Return Analysis', fontsize=16, fontweight='bold')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **NVDA demonstrated exceptional performance** with the highest annualized return (140.64%) and best Sharpe ratio (2.73), despite high volatility.\n",
    "\n",
    "2. **Portfolio strategy comparison** showed that the Equal-Weight portfolio achieved higher returns (64.29%) than the Inverse-Volatility portfolio (53.61%), but with slightly higher volatility.\n",
    "\n",
    "3. **Correlation analysis** revealed that most tech stocks are positively correlated (0.37-0.55), indicating limited diversification benefits within this sector.\n",
    "\n",
    "4. **Volatility patterns** show TSLA has the highest volatility (60.66%), while MSFT provides the most stability (23.39%).\n",
    "\n",
    "### Recommendations:\n",
    "\n",
    "1. **Consider sector diversification** beyond tech stocks to reduce correlation risk\n",
    "2. **Monitor NVDA exposure** carefully due to its high volatility despite strong returns\n",
    "3. **Implement periodic rebalancing** to maintain target portfolio weights\n",
    "4. **Use inverse-volatility weighting** for more conservative risk management\n",
    "5. **Set position limits** based on individual risk tolerance and investment goals\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "- Backtest portfolio strategies with different rebalancing frequencies\n",
    "- Analyze sector rotation opportunities\n",
    "- Consider adding alternative assets for better diversification\n",
    "- Implement risk management strategies (stop-loss, position sizing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
